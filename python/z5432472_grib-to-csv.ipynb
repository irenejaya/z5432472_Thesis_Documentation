{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install eccodes Pakcage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install eccodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coverting (.GRIB) to (.csv)\n",
    "\n",
    "Remark:\n",
    "\n",
    "- base_dir is the directory that contains all the files that we need to convert in a folder\n",
    "- (.GRIB) file should be in a folder with format name of: Year-Month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = r\"C:\\Users\\Irene\\OneDrive - UNSW\\UNSW\\Courses Study\\Research Thesis\\Py\\nwp_preprocess\\nwp-datasets-lead-6hr\"\n",
    "start_year = 2018\n",
    "start_month = 12\n",
    "end_year = 2020\n",
    "end_month = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eccodes\n",
    "import csv\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def grib_to_csv(grib_file, csv_file):\n",
    "    with open(grib_file, 'rb') as f:\n",
    "        gid = eccodes.codes_grib_new_from_file(f)\n",
    "        \n",
    "        if gid is None:\n",
    "            raise ValueError(f\"No valid GRIB found in file: {grib_file}\")\n",
    "        \n",
    "        keys = ['Date', 'Time', 'Latitude', 'Longitude', 'Value']\n",
    "        \n",
    "        with open(csv_file, 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow(keys)\n",
    "            \n",
    "            while gid is not None:\n",
    "                lats = eccodes.codes_get_array(gid, 'latitudes')\n",
    "                lons = eccodes.codes_get_array(gid, 'longitudes')\n",
    "                values = eccodes.codes_get_array(gid, 'values')\n",
    "                data_date = eccodes.codes_get(gid, 'dataDate')\n",
    "                data_time = eccodes.codes_get(gid, 'dataTime')\n",
    "                \n",
    "                date_str = f\"{str(data_date)[:4]}-{str(data_date)[4:6]}-{str(data_date)[6:]}\"\n",
    "                time_str = f\"{str(data_time).zfill(4)[:2]}:{str(data_time).zfill(4)[2:]}\"\n",
    "                \n",
    "                for lat, lon, value in zip(lats, lons, values):\n",
    "                    row = [date_str, time_str, lat, lon, value]\n",
    "                    writer.writerow(row)\n",
    "                \n",
    "                eccodes.codes_release(gid)\n",
    "                gid = eccodes.codes_grib_new_from_file(f)\n",
    "    print(f'GRIB data has been successfully converted to {csv_file}')\n",
    "\n",
    "def convert_all_grib_to_csv(base_dir, start_year, start_month, end_year, end_month):\n",
    "    current_date = datetime(start_year, start_month, 1)\n",
    "    end_date = datetime(end_year, end_month, 1)\n",
    "    \n",
    "    while current_date <= end_date:\n",
    "        year_month_str = current_date.strftime(\"%Y-%m\")\n",
    "        grib_file_path = os.path.join(base_dir, year_month_str, f\"6hr_{year_month_str.replace('-', '.')}.grib\")\n",
    "        csv_file_path = os.path.join(base_dir, year_month_str, f\"6hr_{year_month_str.replace('-', '.')}.csv\")\n",
    "        \n",
    "        if os.path.exists(grib_file_path):\n",
    "            try:\n",
    "                grib_to_csv(grib_file_path, csv_file_path)\n",
    "            except ValueError as e:\n",
    "                print(e)\n",
    "        else:\n",
    "            print(f\"File not found: {grib_file_path}\")\n",
    "        \n",
    "        current_date = datetime(current_date.year + (current_date.month // 12), (current_date.month % 12) + 1, 1)\n",
    "\n",
    "convert_all_grib_to_csv(base_dir, start_year, start_month, end_year, end_month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter (.csv) based on Latitudes and Longitudes Needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def filter_and_process_csv_data(csv_file, filtered_csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Filter the data for the specified latitude and longitude values\n",
    "    filtered_df = df[\n",
    "        ((df['Latitude'] == -17.5) & (df['Longitude'] == 177.5)) |\n",
    "        ((df['Latitude'] == -17.5) & (df['Longitude'] == 178.0)) |\n",
    "        ((df['Latitude'] == -18.0) & (df['Longitude'] == 177.5)) |\n",
    "        ((df['Latitude'] == -18.0) & (df['Longitude'] == 178.0)) |\n",
    "        ((df['Latitude'] == -18.0) & (df['Longitude'] == 178.5))\n",
    "    ]\n",
    "    \n",
    "    # Sort the data by Latitude, Longitude, Date, and Time\n",
    "    filtered_df = filtered_df.sort_values(by=['Latitude', 'Longitude', 'Date', 'Time'])\n",
    "    \n",
    "    # Modify the time values\n",
    "    times = ['06', '12', '18', '24']\n",
    "    filtered_df['Time'] = filtered_df.groupby(['Latitude', 'Longitude', 'Date']).cumcount().map(lambda x: times[x % 4])\n",
    "    \n",
    "    filtered_df.to_csv(filtered_csv_file, index=False)\n",
    "    print(f'Filtered and processed data has been saved to {filtered_csv_file}')\n",
    "\n",
    "def filter_and_process_all_csv(base_dir, start_year, start_month, end_year, end_month):\n",
    "    current_date = datetime(start_year, start_month, 1)\n",
    "    end_date = datetime(end_year, end_month, 1)\n",
    "    \n",
    "    while current_date <= end_date:\n",
    "        year_month_str = current_date.strftime(\"%Y-%m\")\n",
    "        csv_file_path = os.path.join(base_dir, year_month_str, f\"6hr_{year_month_str.replace('-', '.')}.csv\")\n",
    "        filtered_csv_file_path = os.path.join(base_dir, year_month_str, f\"filtered_6hr_{year_month_str.replace('-', '.')}.csv\")\n",
    "        \n",
    "        if os.path.exists(csv_file_path):\n",
    "            filter_and_process_csv_data(csv_file_path, filtered_csv_file_path)\n",
    "        else:\n",
    "            print(f\"File not found: {csv_file_path}\")\n",
    "        \n",
    "        current_date = datetime(current_date.year + (current_date.month // 12), (current_date.month % 12) + 1, 1)\n",
    "\n",
    "filter_and_process_all_csv(base_dir, start_year, start_month, end_year, end_month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assign Station ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Define station IDs and their corresponding latitudes and longitudes\n",
    "stations = {\n",
    "    '778601': {'Latitude': -18.0, 'Longitude': 177.5},\n",
    "    '1770001': {'Latitude': -18.0, 'Longitude': 178.0},\n",
    "    '2216302': {'Latitude': -18.0, 'Longitude': 178.5},\n",
    "    '1127500': {'Latitude': -17.5, 'Longitude': 177.5},\n",
    "    '177599': {'Latitude': -17.5, 'Longitude': 178.0}\n",
    "}\n",
    "\n",
    "def create_station_data(filtered_csv_file, station_csv_file):\n",
    "    df = pd.read_csv(filtered_csv_file)\n",
    "    \n",
    "    # Create a new DataFrame for the output\n",
    "    output_df = pd.DataFrame(columns=['Date', 'Time'] + list(stations.keys()))\n",
    "    \n",
    "    # Populate the new DataFrame with values from the filtered CSV file\n",
    "    for _, row in df.iterrows():\n",
    "        date, time, latitude, longitude, value = row['Date'], row['Time'], row['Latitude'], row['Longitude'], row['Value']\n",
    "        \n",
    "        # Find the station ID corresponding to the latitude and longitude\n",
    "        for station_id, coords in stations.items():\n",
    "            if coords['Latitude'] == latitude and coords['Longitude'] == longitude:\n",
    "                # Check if the (date, time) combination already exists in the output DataFrame\n",
    "                existing_row = output_df[(output_df['Date'] == date) & (output_df['Time'] == time)]\n",
    "                if existing_row.empty:\n",
    "                    # Add a new row for the (date, time) combination\n",
    "                    new_row = {'Date': date, 'Time': time, station_id: value}\n",
    "                    output_df = pd.concat([output_df, pd.DataFrame(new_row, index=[0])], ignore_index=True)\n",
    "                else:\n",
    "                    # Update the existing row with the value for the corresponding station ID\n",
    "                    output_df.loc[(output_df['Date'] == date) & (output_df['Time'] == time), station_id] = value\n",
    "    \n",
    "    # Sort columns to match the required output order\n",
    "    sorted_columns = ['Date', 'Time'] + list(stations.keys())\n",
    "    output_df = output_df[sorted_columns]\n",
    "    \n",
    "    # Save the resulting DataFrame to a CSV file\n",
    "    output_df.to_csv(station_csv_file, index=False)\n",
    "    print(f'Station data has been saved to {station_csv_file}')\n",
    "\n",
    "def process_all_filtered_csv(base_dir, start_year, start_month, end_year, end_month):\n",
    "    current_date = datetime(start_year, start_month, 1)\n",
    "    end_date = datetime(end_year, end_month, 1)\n",
    "    \n",
    "    while current_date <= end_date:\n",
    "        year_month_str = current_date.strftime(\"%Y-%m\")\n",
    "        filtered_csv_file_path = os.path.join(base_dir, year_month_str, f\"filtered_6hr_{year_month_str.replace('-', '.')}.csv\")\n",
    "        station_csv_file_path = os.path.join(base_dir, year_month_str, f\"station_6hr_{year_month_str.replace('-', '.')}.csv\")\n",
    "        \n",
    "        if os.path.exists(filtered_csv_file_path):\n",
    "            create_station_data(filtered_csv_file_path, station_csv_file_path)\n",
    "        else:\n",
    "            print(f\"File not found: {filtered_csv_file_path}\")\n",
    "        \n",
    "        if current_date.month == 12:\n",
    "            current_date = datetime(current_date.year + 1, 1, 1)\n",
    "        else:\n",
    "            current_date = datetime(current_date.year, current_date.month + 1, 1)\n",
    "\n",
    "process_all_filtered_csv(base_dir, start_year, start_month, end_year, end_month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine All into 1 single (.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def combine_station_csv_files(base_dir, start_year, start_month, end_year, end_month, output_file):\n",
    "    all_data = []\n",
    "\n",
    "    current_date = datetime(start_year, start_month, 1)\n",
    "    end_date = datetime(end_year, end_month, 1)\n",
    "    \n",
    "    while current_date <= end_date:\n",
    "        year_month_str = current_date.strftime(\"%Y-%m\")\n",
    "        station_csv_file_path = os.path.join(base_dir, year_month_str, f\"station_6hr_{year_month_str.replace('-', '.')}.csv\")\n",
    "        \n",
    "        if os.path.exists(station_csv_file_path):\n",
    "            df = pd.read_csv(station_csv_file_path)\n",
    "            all_data.append(df)\n",
    "        else:\n",
    "            print(f\"File not found: {station_csv_file_path}\")\n",
    "        \n",
    "        if current_date.month == 12:\n",
    "            current_date = datetime(current_date.year + 1, 1, 1)\n",
    "        else:\n",
    "            current_date = datetime(current_date.year, current_date.month + 1, 1)\n",
    "\n",
    "    if all_data:\n",
    "        combined_df = pd.concat(all_data)\n",
    "        combined_df = combined_df.sort_values(by=['Date', 'Time'])\n",
    "        combined_df.to_csv(output_file, index=False)\n",
    "        print(f'Combined data has been saved to {output_file}')\n",
    "    else:\n",
    "        print('No data to combine.')\n",
    "\n",
    "# Directory paths and parameters\n",
    "base_dir = r\"C:\\Users\\Irene\\OneDrive - UNSW\\UNSW\\Courses Study\\Research Thesis\\Py\\nwp_preprocess\\nwp-datasets-lead-6hr\"\n",
    "output_dir = os.path.join(base_dir, '0_combined_6hr')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = os.path.join(output_dir, 'combined_6hr.csv')\n",
    "\n",
    "combine_station_csv_files(base_dir, start_year, start_month, end_year, end_month, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
